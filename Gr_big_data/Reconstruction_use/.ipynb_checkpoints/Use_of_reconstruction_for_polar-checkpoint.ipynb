{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808f49e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#from sklearn.metrics import r2_score\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(device)\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "plt.style.use(\"seaborn-talk\") #\"classic\" \"seaborn-talk\" \"seaborn\"\n",
    "path_to_h5 =  \"/home/leonov/Baikal/Gr_big_data/mc_baikal_norm_cut-8_ordered_with_MCarlo.h5\"\n",
    "\n",
    "# можно отделить хвост и отдельно прогнать его по другой сетке\n",
    "def make_set(i, di = 1, tr_set_len = 128,Batch_size = 64, regime = \"train\"):\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "            Data = hf[regime + '/data/'][i*int(tr_set_len) : (i+di)*int(tr_set_len),:32]\n",
    "            Data = torch.FloatTensor(Data.swapaxes(1, -1)) # надо,т.к. второй индекс должен быть количеством   последовательностей\n",
    "            Polar = hf[regime + \"/ev_chars\"][i*int(tr_set_len) : (i+di)*int(tr_set_len),0] #*(np.pi)/180\n",
    "            Polar_rec = hf[regime + '/ev_chars/'][i*int(tr_set_len) : (i+di)*int(tr_set_len),3] #*(np.pi)/180                           \n",
    "            polar_error = torch.FloatTensor(Polar-Polar_rec)\n",
    "            Polar = np.expand_dims(Polar, axis=1)                   \n",
    "            Polar_rec = np.expand_dims(Polar_rec, axis=1)\n",
    "            angles = torch.FloatTensor(np.concatenate((Polar,Polar_rec) ,axis=1))    \n",
    "            Dataset = torch.utils.data.TensorDataset(Data, polar_error, angles) #target\n",
    "            Loader = torch.utils.data.DataLoader(dataset = Dataset, batch_size=Batch_size, drop_last = True) #,sampler = sampler    \n",
    "    return  Loader\n",
    "# вектора в углы\n",
    "def v_to_angles( Predicted, Real, Angles, #predicted - предсказанное отклонение реконструкции от угла /Real =Pol-Pol_reconst\n",
    "                p_hist, p_error_hist, p_error_hist_abs, # Angles: 0- real, 1- reconstruct\n",
    "                p_error_angle_cut_hist, I_want_scatter_plot = False,\n",
    "                min_angle = 10., max_angle = 60.): \n",
    "    final_error = Real - Predicted\n",
    "    final_rec_angle = Angles[:,1] + Predicted\n",
    "    final_rec_angle.view(final_rec_angle.shape[0])\n",
    "    real_angle = Angles[:,0].view(Angles.shape[0])\n",
    "    final_error.view(final_error.shape[0])\n",
    "    if I_want_scatter_plot:\n",
    "        plt.scatter(real_angle.cpu().detach().numpy(),final_rec_angle.cpu().detach().numpy(), s= 0.5 ,color = \"red\",\n",
    "                    alpha =0.35, label = \"Final_Rec\" )\n",
    "        plt.scatter(real_angle.cpu().detach().numpy(),Angles[:,1].cpu().detach().numpy(), s=0.5 ,color = \"blue\",\n",
    "                    alpha =0.35 , label = \"Standart_Rec\" )\n",
    "        plt.xlabel(\"Real polar angle\", fontsize = 10); plt.ylabel(\"Updated reconstructed polar angle\", fontsize = 10)\n",
    "        plt.title(\"Scatter plot for polar angle\", fontsize = 15); plt.ylim(bottom =0 ,top = 92); plt.legend(fontsize = 15)\n",
    "    for error, pol_real,pol_final in zip(final_error,real_angle,final_rec_angle):\n",
    "        try:\n",
    "            p_error_hist[round(error.item(),1)] += 1 # просто ошибка\n",
    "            p_error_hist_abs[round(abs(error.item()),1)] += 1 # модуль ошибки\n",
    "            # for certain angles !!!!!!!!!!!!!!!!!!!!!!!\n",
    "            if (pol_real.item() >= min_angle) and (pol_real.item() <= max_angle): \n",
    "                p_error_angle_cut_hist[round(abs(error.item()),1)] += 1\n",
    "            p_hist[pol_final.short().item()] += 1 # финальная реконструкция полярного угла\n",
    "        except:\n",
    "            print(\"error.shape , final_rec_angle.shape, real_angle.shape, final_error.shape: \",\n",
    "                  error.shape , final_rec_angle.shape, real_angle.shape, final_error.shape)\n",
    "    \n",
    "\n",
    "def loss_plot(list_test, list_train , path , save = True):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(np.arange(len(list_test)), list_test, label='val', linewidth=2)\n",
    "    plt.plot(np.arange(len(list_train)), list_train, label='train', linewidth=2)\n",
    "    plt.title('Loss_plot'); plt.xlabel('iterations'); plt.ylabel('Loss'); plt.legend(); plt.show()\n",
    "    if save == True:\n",
    "        plt.savefig(path)   \n",
    "def res_plot(train_dict,val_dict, path = None,save = True, res_or_polar = \"Resolution \" ,size= 13,\n",
    "            Left =0 ,Right =1.3):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    colours=[\"red\",\"red\"]\n",
    "    names = [\"train\" , \"val\"]\n",
    "    for i, d in enumerate([train_dict,val_dict]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        s = sum(d.values())\n",
    "        prep_inter_s ,inter_s = 0, 0\n",
    "        res_50, res_68 =0,0\n",
    "        for key in list(d.keys()):\n",
    "            if inter_s/s >= 0.68:\n",
    "                alpha = (inter_s-0.68*s)/(inter_s-prep_inter_s) # alpha*inter_s+(1-alpha)*prep_inter_s == 0.68*s\n",
    "                res_68 =round(key + 0.1*alpha,3)  #alpha*(key-0.1)+(1-alpha)*(key)\n",
    "                break\n",
    "            if inter_s/s >= 0.5 and res_50 == 0:\n",
    "                alpha = (inter_s-0.5*s)/(inter_s-prep_inter_s)\n",
    "                res_50 =round(key + 0.1*alpha,3)\n",
    "            prep_inter_s = inter_s \n",
    "            inter_s  += d[key]  \n",
    "        a=plt.step(list(d.keys()), list(d.values()), color=colours[i],alpha = 0.6)\n",
    "        plt.bar(res_50, max(d.values()), width=0.1,label=names[i] + \"50%\" + res_or_polar +\"= \"+str(res_50),\n",
    "                color=\"yellow\" , alpha =0.7 )\n",
    "        plt.bar(res_68, max(d.values()), width=0.1,label=names[i] + \"68%\" + res_or_polar +\" = \"+str(res_68) ,\n",
    "                color=\"orange\",alpha = 0.7)\n",
    "        plt.legend(fontsize= 12); #plt.suptitle(res_or_polar,fontsize =size+3)\n",
    "        plt.xlabel(res_or_polar + \"in_grad\",fontsize= 16); plt.title(res_or_polar + names[i],fontsize= 22)\n",
    "        plt.xlim(right =Right,left = Left)\n",
    "    if save == True:\n",
    "        plt.savefig(path) \n",
    "    plt.show()\n",
    "\n",
    "def angle_hist(hist_polar,path, save =True,size= 13,name = \"train\"): #hist_azimut\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "        plt.figure(figsize= (13,6))\n",
    "        sum_value = sum(hist_polar.values())\n",
    "        Polar=hf[\"/\"+name+\"/ev_chars\"][ : ,0]\n",
    "        Rec_Polar=hf[\"/\"+name+\"/ev_chars\"][ : ,3] \n",
    "        plt.hist(Polar,bins=180,label=\"Real polar angle in \" + name +\" data\",density=True,histtype=\"step\",color=\"blue\")\n",
    "        plt.hist(Rec_Polar,bins=180,label=\"Reconstructed polar angle in \" + name +\" data\",density=True,histtype=\"step\",color=\"green\")\n",
    "        plt.bar(list(hist_polar.keys()), np.array(list(hist_polar.values()))/sum_value, fill = False,\n",
    "                color=\"red\",label= \"Predicted polar angle in \" + name +\" data\")\n",
    "        plt.legend(fontsize = 18); plt.xlabel(\"Polar angle\",fontsize= 25);\n",
    "        plt.title(name+\" polar angle\",fontsize= 30); plt.xlim(right = 95)\n",
    "        if save == True:\n",
    "            plt.savefig(path) \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13102e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(model, scheduler_Exp, scheduler_MultiStep , optimizer,\n",
    "        min_angle = 10. ,max_angle = 80.0,\n",
    "        epochs_num = 25, batch_size = 64,\n",
    "        criterion=torch.nn.L1Loss(),\n",
    "        save_weights = True, save_plot = True, save_resolution = True,  save_angles = True, save_polar_error = True,   \n",
    "        suffix = \"Nu_MAE_Only_Polar_MC_DATA_\",\n",
    "        path_begin = \"/home/leonov/Baikal/Gr_big_data\"):\n",
    "    #path_to_h5 =  \"/home/leonov/Baikal/Gr_big_data/mc_baikal_norm_cut-8_ordered_with_MCarlo.h5\"\n",
    "    tr_set_len = 512*100\n",
    "    seq = [j for j in range(int( 1365465/tr_set_len))]\n",
    "    print('Num of sub-epochs in Epoch = ', len(seq), '\\n')\n",
    "    len_seq = len(seq)\n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "\n",
    "    # здесь будут  (polar error) всех событий\n",
    "    hist_train_polar_error = {round(k,1):0 for k in np.arange(-180.0, 180, 0.1)} \n",
    "    hist_val_polar_error = {round(k,1):0 for k in np.arange(-180.0, 180, 0.1)}\n",
    "    \n",
    "    # здесь будут  abs(polar error) всех событий\n",
    "    hist_train_abs_polar_error = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)} \n",
    "    hist_val_abs_polar_error = {round(k,1):0 for k in np.arange(0.0, 180, 0.1)}\n",
    "    \n",
    "    # здесь будут polar error углов от min_angle до max_angle\n",
    "    hist_train_polar_error_angle_cut = {round(k,1):0 for k in np.arange(0.0, 180., 0.1)} \n",
    "    hist_val_polar_error_angle_cut = {round(k,1):0 for k in np.arange(0.0, 180., 0.1)} \n",
    "    \n",
    "    # гистограммы  предсказанных углов для сравнения с реальным распределением     \n",
    "    hist_train_polar = {k:0 for k in np.arange(-5, 181, 1)}\n",
    "    hist_val_polar = {k:0 for k in np.arange(-5, 181, 1)}   \n",
    "    num = 0\n",
    "    for n in range(1, epochs_num+1):\n",
    "        #training\n",
    "        print('Indeed Epoch = ', n, end = \"     \")\n",
    "        for i in seq:\n",
    "            train_Loader = make_set(i,1,tr_set_len,Batch_size = batch_size, regime = \"train\")\n",
    "            for x_batch,y_batch,angles_batch in train_Loader:\n",
    "                optimizer.zero_grad()\n",
    "                outp = model(x_batch.to(device).float())\n",
    "                outp = outp.view(outp.shape[0])\n",
    "                if outp.shape == y_batch.shape:\n",
    "                    loss =   criterion(outp, y_batch.to(device).float())\n",
    "                else :\n",
    "                    print(\"outp.shape, y_batch.shape = \",outp.shape, y_batch.shape)\n",
    "                    raise ValueError\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # полученный вектор направления превращаю в углы и добавляю в гистограммы\n",
    "                if n == epochs_num:\n",
    "                    v_to_angles(Predicted = outp.view(outp.shape[0]), Real = y_batch.to(device), Angles =angles_batch.to(device),\n",
    "                                p_error_hist = hist_train_polar_error, p_error_hist_abs = hist_train_abs_polar_error,\n",
    "                                p_error_angle_cut_hist = hist_train_polar_error_angle_cut,\n",
    "                                p_hist = hist_train_polar,\n",
    "                                min_angle = min_angle, max_angle = max_angle) # az_hist = hist_train_azimut, to_hists = True\n",
    "            if (num%(len_seq//3) == 0):\n",
    "                loss_train.append(loss.item())\n",
    "                model.eval()\n",
    "                testLoader = make_set(0,-1,1, Batch_size = batch_size, regime = \"val\")\n",
    "                test_loss=0\n",
    "                count=0\n",
    "                for x_test_batch,y_test_batch, _ in testLoader:\n",
    "                    outp = model(x_test_batch.to(device).float())\n",
    "                    outp = outp.view(outp.shape[0])\n",
    "                    if  outp.shape == y_test_batch.shape:\n",
    "                        test_loss +=  criterion(outp,y_test_batch.to(device).float()).item()\n",
    "                    else :\n",
    "                        print(\"outp_test.shape, y_batch_test.shape = \",outp.shape, y_test_batch.shape)\n",
    "                        raise ValueError                       \n",
    "                    count+=1\n",
    "                test_loss /=count\n",
    "                loss_test.append(test_loss)\n",
    "                model.train() #print(\"train_loss = \",loss.item(),\"  val_loss = \",test_loss)\n",
    "            num+=1\n",
    "        scheduler_Exp.step(); scheduler_MultiStep.step()       \n",
    "    model.eval()\n",
    "    # график лосса\n",
    "    loss_plot(loss_test, loss_train , path_begin + \"/Images/Loss/\" + suffix + \"LOSS.png\", \n",
    "              save_plot ) \n",
    "    FinalLoader = make_set(0,-1,1, Batch_size = batch_size, regime = \"val\") # делаю  loader из всего датасета\n",
    "    plt.figure(figsize = (5,5)); plt.subplot(1,1,1)\n",
    "    for x_test_batch,y_test_batch, angles_batch in FinalLoader:\n",
    "        outp = model(x_test_batch.to(device).float())\n",
    "        outp = outp\n",
    "        v_to_angles(Predicted = outp.view(outp.shape[0]), Real = y_test_batch.to(device), I_want_scatter_plot = True,\n",
    "                    Angles =angles_batch.to(device),\n",
    "                    p_error_hist = hist_val_polar_error, p_error_hist_abs = hist_val_abs_polar_error,\n",
    "                    p_error_angle_cut_hist = hist_val_polar_error_angle_cut, p_hist = hist_val_polar,\n",
    "                    min_angle = min_angle, max_angle = max_angle) \n",
    "\n",
    "    if save_weights == True:\n",
    "        torch.save(model.state_dict(), path_begin + \"/states/\" + suffix + \"model\")\n",
    "        torch.save(optimizer.state_dict(), path_begin + \"/states/\" + suffix + \"opt\")        \n",
    "    loss_lists = [loss_train , loss_test]\n",
    "    polar_hists = [hist_train_polar , hist_val_polar]\n",
    "    polar_error = [hist_train_polar_error, hist_val_polar_error,\n",
    "                   hist_train_polar_error_angle_cut, hist_val_polar_error_angle_cut]    \n",
    "    #  гистограмма  финальной ошибки  полярного угла\n",
    "    res_plot(hist_train_polar_error, hist_val_polar_error, \n",
    "             path = path_begin + \"/Images/Polar_Error/\" + suffix+ \"Final_Polar_Error.png\",\n",
    "             save = save_polar_error, res_or_polar = \"Final_Polar_Error \",Left =-2.3 ,Right =2.3)\n",
    "    #  гистограмма модуля финальной ошибки  полярного угла\n",
    "    res_plot(hist_train_abs_polar_error, hist_val_abs_polar_error, \n",
    "             path = path_begin + \"/Images/Polar_Error/\" + suffix+ \"Final_Abs_Polar_Error.png\",\n",
    "             save = save_polar_error, res_or_polar = \"Final_Abs_Polar_Error \",Left =0 ,Right =2.3) \n",
    "    #  гистограмма модуля стандартной ошибки  полярного угла\n",
    "    plt.figure(figsize =(5,5))\n",
    "    with h5py.File(path_to_h5, 'r') as hf:\n",
    "        Polar = hf[\"train\" + \"/ev_chars\"][:,0] \n",
    "        Polar_rec = hf[\"train\" + '/ev_chars/'][:,3]                          \n",
    "        polar_error = np.abs(Polar-Polar_rec)\n",
    "        res_50_rec, res_68_rec = round(np.percentile(polar_error, 50),3), round(np.percentile(polar_error, 68),3)\n",
    "        standart_hist = plt.hist(polar_error, bins =100, color=\"red\" , alpha = 0.5)\n",
    "        polar_error_cut = polar_error[polar_error<1]\n",
    "        plt.bar(res_50_rec, max(standart_hist[0]), width=0.1,label=\"Standart Reconstruction 50% res = \" + str(res_50_rec),\n",
    "                color=\"yellow\" , alpha =0.7 )\n",
    "        plt.bar(res_68_rec, max(standart_hist[0]), width=0.1,label=\"Standart Reconstruction 68% res = \"+str(res_68_rec) ,\n",
    "                color=\"orange\",alpha = 0.7)\n",
    "        plt.xlim(right = 2,left = 0); plt.xlabel(\"Standart Reconstruction error\"); plt.legend(fontsize = 15)\n",
    "    plt.show()\n",
    "    #  гистограмма ошибок  полярного угла для определенных углов\n",
    "    res_plot(hist_train_polar_error_angle_cut, hist_val_polar_error_angle_cut, \n",
    "             path = path_begin + \"/Images/Polar_Error_Angle_Cut/\" + suffix+ \"Final_Polar_Error_Angle_Cut.png\",\n",
    "             save = save_polar_error, res_or_polar = \"Final_Polar_Error_Angle_Cut \",Left =0 ,Right =2.3) \n",
    "    \n",
    "    #гистограммы углов\n",
    "    angle_hist(hist_train_polar, name='train',\n",
    "               path = path_begin + \"/Images/Angles/\" + suffix + \"Angles_train.png\", \n",
    "               save = save_angles)\n",
    "    angle_hist(hist_val_polar, name='val',\n",
    "               path = path_begin + \"/Images/Angles/\" + suffix + \"Angles_val.png\", \n",
    "               save = save_angles)\n",
    "    \n",
    "    model.train()\n",
    "    return  loss_lists, polar_hists ,polar_error \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66d77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "368684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transition_Block(torch.nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.trans_module = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(input_size, input_size*2, kernel_size=3, stride=2,padding=1 , bias = False),\n",
    "            torch.nn.BatchNorm1d(num_features=input_size*2),\n",
    "            torch.nn.PReLU()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        return  self.trans_module(inputs) \n",
    "power = 4\n",
    "bias_mask = False\n",
    "class ResNet_Block_power(torch.nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super().__init__()\n",
    "        self.module = torch.nn.Sequential(    \n",
    "            torch.nn.Conv1d(input_size, input_size*power,  kernel_size=3, stride=1,padding=1,bias = bias_mask),\n",
    "            torch.nn.BatchNorm1d(input_size*power),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*power, input_size*power,  kernel_size=3, stride=1,padding=1,bias = bias_mask),\n",
    "            torch.nn.BatchNorm1d(input_size*power),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.Conv1d(input_size*power,input_size,  kernel_size=3, stride= 1 ,padding=1,bias = bias_mask),\n",
    "            torch.nn.BatchNorm1d(input_size),\n",
    "            torch.nn.PReLU()\n",
    "          )\n",
    "        self.conv = torch.nn.Sequential( \n",
    "            torch.nn.Conv1d(input_size, input_size, kernel_size =1,bias =  bias_mask),\n",
    "            torch.nn.PReLU()\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "          return  (self.module(inputs) +self.conv(inputs))\n",
    "a = torch.ones((512,5 ,32))\n",
    "net_MC_data_polar = torch.nn.Sequential(    \n",
    "    torch.nn.Conv1d(5, 5,  kernel_size= 3 , stride = 1 ,padding= 1 ,bias = bias_mask),\n",
    "    torch.nn.BatchNorm1d(5),\n",
    "    torch.nn.PReLU(),\n",
    "    ResNet_Block_power(5), #32\n",
    "    ResNet_Block_power(5), \n",
    "    Transition_Block(5), #16\n",
    "    ResNet_Block_power(10),\n",
    "    ResNet_Block_power(10), #16\n",
    "    Transition_Block(10), #8\n",
    "    ResNet_Block_power(20),\n",
    "    ResNet_Block_power(20), \n",
    "    Transition_Block(20), #4\n",
    "    ResNet_Block_power(40),\n",
    "    ResNet_Block_power(40), # 4\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(160,160),\n",
    "    torch.nn.BatchNorm1d(160),\n",
    "    torch.nn.PReLU(),\n",
    "    torch.nn.Linear(160,160),\n",
    "    torch.nn.BatchNorm1d(160),\n",
    "    torch.nn.PReLU(),\n",
    "    torch.nn.Linear(160 ,1)\n",
    ") \n",
    "\n",
    "\n",
    "print(net_MC_data_polar(a).shape )\n",
    "sum(p.numel() for p in net_MC_data_polar.parameters()   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662745c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of sub-epochs in Epoch =  26 \n",
      "\n",
      "Indeed Epoch =  1     "
     ]
    }
   ],
   "source": [
    "model = net_MC_data_polar.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "sch_Exp = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.7)\n",
    "sch_MultiStep = torch.optim.lr_scheduler.MultiStepLR(opt,milestones=[6,12,18,24,30], gamma=1.0) \n",
    "loss_lists, polar_hists ,polar_error =fitting(model, sch_Exp , sch_MultiStep, opt,\n",
    "                                                                       suffix = \"Nu_MAE_only_polar_MC_use_rec\",\n",
    "                                                                       epochs_num = 10, batch_size =64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d913b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aa00832",
   "metadata": {},
   "source": [
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dee71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_MSE = net_MC_data_polar.to(device)\n",
    "opt_MSE = torch.optim.Adam(model_MSE.parameters(),lr=1e-4)\n",
    "\n",
    "sch_Exp_MSE = torch.optim.lr_scheduler.ExponentialLR(opt_MSE, gamma=0.95)\n",
    "sch_MultiStep_MSE = torch.optim.lr_scheduler.MultiStepLR(opt_MSE,milestones=[6,12,18,24,30], gamma=0.9) \n",
    "loss_lists, polar_hists ,polar_error =fitting(model_MSE, sch_Exp_MSE , sch_MultiStep_MSE, opt_MSE,\n",
    "                                              criterion=torch.nn.MSELoss(),\n",
    "                                                                       suffix = \"Nu_MAE_only_polar_MC_use_rec\",\n",
    "                                                                       epochs_num = 15, batch_size =64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77b7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
