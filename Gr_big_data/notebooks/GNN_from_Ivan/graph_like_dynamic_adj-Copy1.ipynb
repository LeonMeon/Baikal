{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9c0a1e",
   "metadata": {},
   "source": [
    "Replace attentions with dynamic adj\n",
    "\n",
    "Возможные изменения:\n",
    "\n",
    "Мастер-вершина\n",
    "\n",
    "Reduce adj matrix to real vert only\n",
    "\n",
    "e_ij - кодировка ребр; дорого по памяти\n",
    "\n",
    "U-GNN - свертки графа с уменьшением размерности: use clustering?\n",
    "\n",
    "RNN in GNN?\n",
    "\n",
    "U-net cnn: 99.66%\n",
    "\n",
    "LR: ???\n",
    "\n",
    "pre-rnn stabilizes training\n",
    "\n",
    "graph-nn in unet (conv+gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccb9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef64bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f201cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 14:39:40.099539: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 14:39:40.596444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 17363 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:44:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "h5f = '/home/ivkhar/Baikal/data/mc_baikal_norm_cut-0_ordered_equal_big.h5'\n",
    "max_len = 110\n",
    "batch_size = 16\n",
    "\n",
    "# generator without shuffling\n",
    "class generator_no_shuffle:\n",
    "    \n",
    "    def __init__(self, file, regime, batch_size, return_reminder):\n",
    "        self.file = file\n",
    "        self.regime = regime\n",
    "        self.batch_size = batch_size\n",
    "        self.return_reminder = return_reminder\n",
    "        with h5.File(self.file,'r') as hf:\n",
    "            self.num = hf[self.regime+'/data'].shape[0]     \n",
    "        self.batch_num = self.num // self.batch_size\n",
    "        if return_reminder:\n",
    "            self.gen_num = self.num\n",
    "        else:\n",
    "            self.gen_num = self.batch_num*self.batch_size\n",
    "\n",
    "    def __call__(self):\n",
    "        start = 0\n",
    "        stop = self.batch_size\n",
    "        with h5.File(self.file, 'r') as hf:\n",
    "            for i in range(self.batch_num):\n",
    "                mask = hf[self.regime+'/mask'][start:stop]\n",
    "                mask_channel = np.expand_dims( mask, axis=-1 )\n",
    "                labels = hf[self.regime+'/labels_signal_noise'][start:stop]\n",
    "                yield ( np.concatenate((hf[self.regime+'/data'][start:stop],mask_channel), axis=-1), \n",
    "                  labels )\n",
    "                start += self.batch_size\n",
    "                stop += self.batch_size\n",
    "            if self.return_reminder:\n",
    "                mask = hf[self.regime+'/mask'][start:stop]\n",
    "                mask_channel = np.expand_dims( mask, axis=-1 )\n",
    "                labels = hf[self.regime+'/labels_signal_noise'][start:stop]\n",
    "                yield ( np.concatenate((hf[self.regime+'/data'][start:stop],mask_channel), axis=-1), \n",
    "                  labels )\n",
    "\n",
    "# generator with shuffling\n",
    "class generator_with_shuffle:\n",
    "    \n",
    "    def __init__(self, file, regime, batch_size, buffer_size, return_reminder):\n",
    "        self.file = file\n",
    "        self.regime = regime\n",
    "        self.batch_size = batch_size\n",
    "        self.return_reminder = return_reminder\n",
    "        self.buffer_size = buffer_size\n",
    "        with h5.File(self.file,'r') as hf:\n",
    "            self.num = hf[self.regime+'/data/'].shape[0] \n",
    "        self.batch_num = (self.num-self.buffer_size) // self.batch_size\n",
    "        self.last_batches_num = self.buffer_size // self.batch_size\n",
    "        if return_reminder:\n",
    "            self.gen_num = self.num\n",
    "        else:\n",
    "            self.gen_num = (self.batch_num+self.last_batches_num)*self.batch_size\n",
    "\n",
    "    def __call__(self):\n",
    "        start = self.buffer_size\n",
    "        stop = self.buffer_size + self.batch_size\n",
    "        with h5.File(self.file, 'r') as hf:\n",
    "            mask = hf[self.regime+'/mask'][:self.buffer_size]\n",
    "            mask_channel = np.expand_dims( mask, axis=-1 )\n",
    "            buffer_data = np.concatenate((hf[self.regime+'/data'][:self.buffer_size],mask_channel), axis=-1)\n",
    "            buffer_labels = hf[self.regime+'/labels_signal_noise'][:self.buffer_size]\n",
    "            for i in range(self.batch_num):\n",
    "                idxs = rd.sample( range(self.buffer_size), k=self.batch_size )\n",
    "                yield ( buffer_data[idxs] , buffer_labels[idxs] )\n",
    "                mask = hf[self.regime+'/mask'][start:stop]\n",
    "                mask_channel = np.expand_dims( mask, axis=-1 )\n",
    "                buffer_data[idxs] = np.concatenate((hf[self.regime+'/data'][start:stop],mask_channel),axis=-1)\n",
    "                labels = hf[self.regime+'/labels_signal_noise'][start:stop]\n",
    "                buffer_labels[idxs] = labels\n",
    "                start += self.batch_size\n",
    "                stop += self.batch_size\n",
    "            # fill the buffer with left data, if any\n",
    "            # this a bit increases buffer size and MIGT BE COSTLY\n",
    "            mask = hf[self.regime+'/mask'][start:stop]\n",
    "            mask_channel = np.expand_dims( mask, axis=-1 )\n",
    "            buffer_data = np.concatenate( (buffer_data,np.concatenate((hf[self.regime+'/data'][start:stop],mask_channel),axis=-1)), axis=0 )\n",
    "            labels = hf[self.regime+'/labels_signal_noise'][start:stop]\n",
    "            buffer_labels  = np.concatenate( (buffer_labels,labels), axis=0 )\n",
    "            sh_idxs = rd.sample( range(buffer_labels.shape[0]), k=buffer_labels.shape[0] )\n",
    "            start = 0\n",
    "            stop = self.batch_size\n",
    "            for i in range(self.last_batches_num):\n",
    "                idxs = sh_idxs[start:stop]\n",
    "                yield ( buffer_data[idxs], buffer_labels[idxs] )\n",
    "                start += self.batch_size\n",
    "                stop += self.batch_size\n",
    "            if self.return_reminder:\n",
    "                idxs = sh_idxs[start:stop]\n",
    "                yield ( buffer_data[idxs], buffer_labels[idxs])\n",
    "\n",
    "### MADE SO BATCH SIZE IS CONSTANT AND NO REMINDER\n",
    "def make_datasets(h5f,make_generator_shuffle,return_batch_reminder,train_batch_size,train_buffer_size,test_batch_size):\n",
    "    # generator for training data\n",
    "    if make_generator_shuffle:\n",
    "        tr_generator = generator_with_shuffle(h5f,'train',train_batch_size,train_buffer_size,return_batch_reminder)\n",
    "    else:\n",
    "        tr_generator = generator_no_shuffle(h5f,'train',train_batch_size,return_batch_reminder)\n",
    "    if return_batch_reminder:\n",
    "        # size of the last batch is unknown\n",
    "        tr_batch_size = None\n",
    "    else:\n",
    "        tr_batch_size = train_batch_size\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_generator( tr_generator, \n",
    "                        output_signature=( tf.TensorSpec(shape=(tr_batch_size,max_len,6)), tf.TensorSpec(shape=(tr_batch_size,max_len,2))\n",
    "                                         ) )\n",
    "\n",
    "    if make_generator_shuffle:\n",
    "        train_dataset = train_dataset.repeat(-1).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        train_dataset = train_dataset.repeat(-1).shuffle(num_batch_shuffle)\n",
    "\n",
    "    # generator for validation data\n",
    "    te_generator = generator_no_shuffle(h5f,'test',test_batch_size,False)\n",
    "    te_batch_size = tr_batch_size\n",
    "    test_dataset = tf.data.Dataset.from_generator( te_generator, \n",
    "                        output_signature=( tf.TensorSpec(shape=(tr_batch_size,max_len,6)), tf.TensorSpec(shape=(tr_batch_size,max_len,2))\n",
    "                                          ) )\n",
    "    \n",
    "    test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = make_datasets(h5f,True,False,batch_size,500*batch_size,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e50bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pre-transforms nodes encodings\n",
    "# returns transformed encoding plus initial\n",
    "# pass empty filters to avoid new encs\n",
    "# in case k!=1 neighbours effect the final encoding\n",
    "\n",
    "# (bs,om,c) -> (bs,om,c')\n",
    "class NodesEncoder(tf.keras.layers.Layer):\n",
    "      \n",
    "    def __init__(self, filters, kernels, activation):\n",
    "        super(NodesEncoder, self).__init__()\n",
    "        assert len(filters)==len(kernels)\n",
    "        self.num_layers = len(filters)\n",
    "        self.conv_layers = [ tf.keras.layers.Conv1D(f, k, padding='same') for (f,k) in zip(filters,kernels) ]\n",
    "        self.activation = activation\n",
    "        self.filters = filters\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        if self.num_layers==0:\n",
    "            self.out_encs_length = input_shape[-1]\n",
    "        else:\n",
    "            self.out_encs_length = self.filters[-1]+input_shape[-1]\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        init_x = x\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)\n",
    "            x = self.activation(x)\n",
    "            x = tf.concat((x,init_x),axis=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54a597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates messages for pairs of nodes\n",
    "# k=(1,1) reduces to usual dense\n",
    "\n",
    "# (bs,om,om,c) -> (bs,om,om,c')\n",
    "class MessageCreator(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, filters, kernels, activation):\n",
    "        super(MessageCreator, self).__init__()\n",
    "        self.conv_layers = [ tf.keras.layers.Conv2D(f, k, padding='same') for (f,k) in zip(filters,kernels) ]\n",
    "        self.activation = activation\n",
    "\n",
    "    def call(self, x):\n",
    "        for lr in self.conv_layers:\n",
    "            x = lr(x)\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe913f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### message parser\n",
    "# reduces all messages to single message\n",
    "\n",
    "# (bs,om,om,c) -> (bs,om,c')\n",
    "class MessageParser(tf.keras.layers.Layer):\n",
    "  \n",
    "    # filters, kernels, strides - sequances\n",
    "    def __init__(self, filters, kernels, strides, units, activation, take_mean):\n",
    "        super(MessageParser, self).__init__()\n",
    "        assert len(filters)==len(kernels)\n",
    "        assert len(filters)==len(strides)\n",
    "        self.conv_layers = [ tf.keras.layers.Conv2D(f, k, strides=s, padding='same') for (f,k,s) in zip(filters,kernels,strides) ]\n",
    "        self.dence_layers = [ tf.keras.layers.Dense(un) for un in units ]\n",
    "        self.activation = activation\n",
    "        self.max_poolings = [  tf.keras.layers.MaxPooling2D(pool_size=(1,2)) for f in filters ]\n",
    "        self.take_mean = take_mean\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for (conv,mp) in zip(self.conv_layers,self.max_poolings):\n",
    "            x = conv(x)\n",
    "            x = self.activation(x)\n",
    "            x = mp(x)\n",
    "        # (bs,om,om',c')\n",
    "        if self.take_mean:\n",
    "            x = tf.math.reduce_mean(x, axis=2) # (bs,om,c')\n",
    "        else:\n",
    "            x = tf.reshape(x, (x.shape[0],x.shape[1],-1)) # (bs,om,c')\n",
    "        for de in self.dence_layers:\n",
    "            x = de(x)\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4969e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### state updater\n",
    "\n",
    "# (bs,om,c) -> (bs,om,c')\n",
    "class StateUpdater(tf.keras.layers.Layer):\n",
    "  \n",
    "    def __init__(self, units, activations):\n",
    "        super(StateUpdater, self).__init__()\n",
    "        self.dense_layers = [ tf.keras.layers.Dense(u) for u in units ]\n",
    "        self.activations = [ act for act in activations ]\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for (dense,ac) in zip(self.dense_layers,self.activations):\n",
    "            x = dense(x)\n",
    "            x = ac(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c986d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### adj updater\n",
    "\n",
    "# (bs,om,om,c)x(bs,om,om,1) -> (bs,om,om,1)\n",
    "class AdjUpdater(tf.keras.layers.Layer):\n",
    "  \n",
    "    def __init__(self, v_filters, v_kernels, v_activation, j_filters, j_kernels, j_activations):\n",
    "        super(AdjUpdater, self).__init__()\n",
    "        assert len(v_filters)==len(v_kernels)\n",
    "        assert len(j_filters)==len(j_kernels)\n",
    "        self.conv_layers_vert = [ tf.keras.layers.Conv2D(f, k, padding='same') for (f,k) in zip(v_filters,v_kernels) ]\n",
    "        self.conv_layers_joint = [ tf.keras.layers.Conv2D(f, k, padding='same') for (f,k) in zip(j_filters,j_kernels) ]\n",
    "        self.v_activation = v_activation\n",
    "        self.j_activations = j_activations\n",
    "\n",
    "    def call(self, vert, adj):\n",
    "        # preprocess verticies\n",
    "        x = vert\n",
    "        for lr in self.conv_layers_vert:\n",
    "            x = lr(x)\n",
    "            x = self.v_activation(x)\n",
    "        # update\n",
    "        x = tf.concat((x,adj), axis=-1)\n",
    "        for (lr,ac) in zip(self.conv_layers_joint,self.j_activations):\n",
    "            x = lr(x)\n",
    "            x = ac(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f57c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE TF WHERE WITH ADJ ???\n",
    "class GraphStepLayer(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, nodes_encoder, message_creator, message_parser, state_updater, adj_updater):\n",
    "        super(GraphStepLayer, self).__init__()\n",
    "        self.nodes_encoder = nodes_encoder\n",
    "        self.message_creator = message_creator\n",
    "        self.message_parser = message_parser\n",
    "        self.state_updater = state_updater\n",
    "        self.adj_updater = adj_updater\n",
    "        self.pos_channel = np.expand_dims(np.expand_dims(np.arange(-1,1,2/max_len),axis=-1),axis=0)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.nodes_encoder.build(input_shape)\n",
    "        \n",
    "    # (bs,om,c) -> (bs,om,om,2c)\n",
    "    def make_pairs(self, vert):\n",
    "        vert_exp_1 = tf.expand_dims(vert,axis=1) # (bs,1,om,c)\n",
    "        vert_exp_2 = tf.expand_dims(vert,axis=2) # (bs,om,1,c)\n",
    "        helper = tf.fill( (vert.shape[0],vert.shape[1],vert.shape[1],1), 1. )\n",
    "        rel_vert = helper*vert_exp_2 # (bs, om, om_targ, c)\n",
    "        base_vert = helper*vert_exp_1 # (bs, om_base, om, c)\n",
    "        pairs = tf.concat((rel_vert,base_vert),axis=-1) # (bs, om_base, om_target, 2c)\n",
    "        return pairs\n",
    "        \n",
    "    def call(self, inputes):\n",
    "        (vert, adj) = inputes\n",
    "        # encode nodes for message passing\n",
    "        node_encs = self.nodes_encoder(vert) # (bs,om,c)\n",
    "        # prepare messages\n",
    "        # add position channel\n",
    "        pos_encs = np.repeat( self.pos_channel, vert.shape[0], axis=0 )\n",
    "        node_encs_pos = tf.concat( (node_encs,pos_encs), axis=-1 ) # (bs,om,c)\n",
    "        pairs = self.make_pairs(node_encs_pos) # (b,om,om,2c)\n",
    "        # use adj as attention\n",
    "        #messages = tf.where(init_adj, self.message_creator(adj*pairs), [0]) # (b,om,om,c')\n",
    "        messages = self.message_creator(adj*pairs) # (b,om,om,c')\n",
    "        # prepare single message\n",
    "        mess = self.message_parser(messages) # (b,om,c)\n",
    "        # update states\n",
    "        update_from = tf.concat((node_encs,mess), axis=-1) # (b, om, ch')\n",
    "        out_encs = self.state_updater( update_from ) # (b, om, ch)\n",
    "        # update adj matrix\n",
    "        pairs_n = self.make_pairs(out_encs)\n",
    "        adj_n = self.adj_updater(pairs_n,adj)\n",
    "        return (out_encs, adj_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d327cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph layer with residual connection\n",
    "class GraphResLayer(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, nodes_encoders, message_creators, message_parsers, state_updaters, adj_updaters):\n",
    "        super(GraphResLayer, self).__init__()\n",
    "        self.gr_layers = []\n",
    "        for i in range(2):\n",
    "            gr_layer = GraphStepLayer( nodes_encoders[i], message_creators[i], message_parsers[i], state_updaters[i], adj_updaters[i])\n",
    "            self.gr_layers.append(gr_layer)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        (vert, adj) = inputs\n",
    "        # pass through fist layer\n",
    "        (vert1, adj1) = self.gr_layers[0]((vert, adj))\n",
    "        # second\n",
    "        (vert2, adj2) = self.gr_layers[1]((vert1, adj1))\n",
    "        # concat\n",
    "        vert_res = tf.concat((vert1,vert2), axis=-1)\n",
    "        return (vert_res, (adj1+adj2)/2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c3368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make graph model\n",
    "class GraphLikeModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, pre_layer, gnn_layers, post_layer, k_nearest):\n",
    "        super(GraphLikeModel, self).__init__()\n",
    "        self.pre_layer = pre_layer\n",
    "        self.graph_layers = gnn_layers\n",
    "        self.post_layer = post_layer\n",
    "        if k_nearest>0:\n",
    "            te = [ np.expand_dims(np.eye(max_len),axis=0)]\n",
    "            for i in range(1,k_nearest):\n",
    "                te.append(np.expand_dims(np.eye(max_len, k=i, dtype=np.float32),axis=0))\n",
    "                te.append(np.expand_dims(np.eye(max_len, k=-i, dtype=np.float32),axis=0))\n",
    "            self.full_adj = tf.expand_dims( np.sum( np.concatenate(te, axis=0), axis=0 ), axis=-1)\n",
    "        else:\n",
    "            self.full_adj = tf.fill((1,max_len,max_len,1), 1.)\n",
    "        self.full_adj = tf.cast(self.full_adj, tf.float32)\n",
    "              \n",
    "    def call(self, x):\n",
    "        # readout mask and make adj matrix\n",
    "        mask = tf.cast(x[:,:,-1:], tf.float32) # (bs,om,1)\n",
    "        adj = self.full_adj*tf.expand_dims(mask,axis=1)*tf.expand_dims(mask,axis=2) # (bs,om,om,1)\n",
    "        # normilize, not proper at first layer\n",
    "        adj = tf.keras.activations.softmax(adj)\n",
    "        # preprocess inputs\n",
    "        x = self.pre_layer(x)\n",
    "        # pass via graph layers\n",
    "        for gr_lr in self.graph_layers:\n",
    "            (x, adj) = gr_lr((x,adj))\n",
    "        # postprocess\n",
    "        x = self.post_layer(x)\n",
    "        # make preds\n",
    "        preds = tf.where( tf.cast(mask,bool), x, tf.constant([0.,1.]) )\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15c929f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, lr):\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702e7610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "selu = tf.keras.activations.selu\n",
    "relu = tf.keras.activations.relu\n",
    "sigmoid = tf.keras.activations.sigmoid\n",
    "softmax = tf.keras.activations.softmax\n",
    "\n",
    "depth = 3\n",
    "filts = 128\n",
    "\n",
    "# create nodes encoders\n",
    "node_enc_filters = [[filts] for i in range(depth)]\n",
    "node_enc_kernels =  [[1] for i in range(depth)]\n",
    "node_enc_activation = selu\n",
    "nodes_encoders = []\n",
    "for (filters,kernels) in zip(node_enc_filters,node_enc_kernels):\n",
    "    nodes_encoders.append( [NodesEncoder(filters,kernels,node_enc_activation),NodesEncoder(filters,kernels,node_enc_activation)] )\n",
    "\n",
    "# make message creators\n",
    "# 2d kernels\n",
    "mess_cr_filters = [[filts] for i in range(depth)]\n",
    "mess_cr_kernels = [[(1,1)] for i in range(depth)]\n",
    "mess_cr_activation = selu\n",
    "mess_crs = []\n",
    "for (filters,kernels) in zip(mess_cr_filters,mess_cr_kernels):\n",
    "    mess_crs.append( [MessageCreator(filters,kernels,mess_cr_activation),MessageCreator(filters,kernels,mess_cr_activation)] )\n",
    "\n",
    "# create message parsers\n",
    "# 2d kernels and strides\n",
    "mess_pars_filters = [32]\n",
    "mess_pars_kernels = [(1,5)]\n",
    "mess_pars_strides = [(1,2)]\n",
    "mess_pars_units = [[filts] for i in range(depth)]\n",
    "mess_pass_activation = selu\n",
    "mess_pars_take_mean = False\n",
    "mess_parsers = []\n",
    "for units in mess_pars_units:\n",
    "    mess_parsers.append( [MessageParser(mess_pars_filters,mess_pars_kernels,mess_pars_strides,units,mess_pass_activation,mess_pars_take_mean),\n",
    "                         MessageParser(mess_pars_filters,mess_pars_kernels,mess_pars_strides,units,mess_pass_activation,mess_pars_take_mean)] )\n",
    "\n",
    "# make adj updateras\n",
    "# 2d kernels\n",
    "adj_v_filters = [[32] for i in range(depth)]\n",
    "adj_v_kernels = [[(1,1)] for i in range(depth)]\n",
    "adj_v_activation = selu\n",
    "adj_j_filters = [[16,1] for i in range(depth)]\n",
    "adj_j_kernels = [[(1,1),(1,1)] for i in range(depth)]\n",
    "att_j_activations = [[selu,sigmoid] for i in range(depth)]\n",
    "adj_upds = []\n",
    "for (v_filters,v_kernels,j_filters,j_kernels,j_act) in zip(adj_v_filters,adj_v_kernels,adj_j_filters,adj_j_kernels,att_j_activations):\n",
    "    adj_upds.append( [AdjUpdater(v_filters,v_kernels,adj_v_activation,j_filters,j_kernels,j_act),AdjUpdater(v_filters,v_kernels,adj_v_activation,j_filters,j_kernels,j_act)] )\n",
    "\n",
    "# make state updaters\n",
    "state_upd_units = [[(3*filts//2)] for i in range(depth)]\n",
    "state_upd_activations = [[selu] for i in range(depth)]\n",
    "state_ups = []\n",
    "for (units,act) in zip(state_upd_units,state_upd_activations):\n",
    "    state_ups.append( [StateUpdater(units,act),StateUpdater(units,act)] )\n",
    "\n",
    "# make graph layers\n",
    "gr_layers = []\n",
    "for (node_enc,mess_cr,mess_pars,adj_upd,state_upd) in zip(nodes_encoders,mess_crs,mess_parsers,adj_upds,state_ups):\n",
    "    gr_layers.append( GraphResLayer(node_enc, mess_cr, mess_pars, state_upd, adj_upd) )\n",
    "    \n",
    "# make pre-layers\n",
    "pre_layer = tf.identity\n",
    "#pre_layer = tf.keras.layers.LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True)\n",
    "\n",
    "# make post_layers\n",
    "post_layer = tf.keras.layers.Dense(2, activation=softmax)\n",
    "\n",
    "# make gnn\n",
    "gnn = GraphLikeModel( pre_layer, gr_layers, post_layer, -1)\n",
    "gnn = compile_model(gnn, 0.0006)\n",
    "\n",
    "print(len(gr_layers))\n",
    "# grads do not exist for the last adj updater as it does not effect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebbbee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carefull with lr and bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac37803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_27/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_27/bias:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_28/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_28/bias:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_29/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_29/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_27/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_27/bias:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_28/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_28/bias:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_29/kernel:0', 'graph_like_model/graph_res_layer_2/graph_step_layer_5/adj_updater_5/conv2d_29/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 14:40:06.249667: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8301\n",
      "2022-05-05 14:40:07.452611: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-05 14:40:07.590259: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 526s 207ms/step - loss: 0.0437 - accuracy: 0.9824 - val_loss: 0.0277 - val_accuracy: 0.9887\n",
      "Epoch 2/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0211 - accuracy: 0.9915 - val_loss: 0.0223 - val_accuracy: 0.9910\n",
      "Epoch 3/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0169 - accuracy: 0.9933 - val_loss: 0.0211 - val_accuracy: 0.9914\n",
      "Epoch 4/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.0167 - val_accuracy: 0.9934\n",
      "Epoch 5/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 6/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.0156 - val_accuracy: 0.9939\n",
      "Epoch 7/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0123 - accuracy: 0.9952 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
      "Epoch 8/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0142 - val_accuracy: 0.9945\n",
      "Epoch 9/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0157 - val_accuracy: 0.9939\n",
      "Epoch 10/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0104 - accuracy: 0.9959 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 11/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 0.0125 - val_accuracy: 0.9952\n",
      "Epoch 12/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0126 - val_accuracy: 0.9952\n",
      "Epoch 13/25\n",
      "2500/2500 [==============================] - 516s 207ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.0121 - val_accuracy: 0.9954\n",
      "Epoch 14/25\n",
      "2500/2500 [==============================] - 517s 207ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0122 - val_accuracy: 0.9954\n",
      "Epoch 15/25\n",
      "1421/2500 [================>.............] - ETA: 3:27 - loss: 0.0093 - accuracy: 0.9964"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1077681/1540791179.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=25, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e15f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560cb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdb143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f3b44962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1107/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1107/bias:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1108/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1108/bias:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1109/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1109/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1107/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1107/bias:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1108/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1108/bias:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1109/kernel:0', 'graph_like_model_34/graph_res_layer_100/graph_step_layer_201/adj_updater_201/conv2d_1109/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 235s 92ms/step - loss: 0.0461 - accuracy: 0.9805 - val_loss: 0.0293 - val_accuracy: 0.9880\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 228s 91ms/step - loss: 0.0241 - accuracy: 0.9902 - val_loss: 0.0235 - val_accuracy: 0.9905\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 231s 92ms/step - loss: 0.0206 - accuracy: 0.9917 - val_loss: 0.0211 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 231s 92ms/step - loss: 0.0191 - accuracy: 0.9923 - val_loss: 0.0215 - val_accuracy: 0.9913\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 232s 93ms/step - loss: 0.0183 - accuracy: 0.9926 - val_loss: 0.0205 - val_accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 230s 92ms/step - loss: 0.0173 - accuracy: 0.9930 - val_loss: 0.0208 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 230s 92ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0208 - val_accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 231s 92ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 0.0194 - val_accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 229s 92ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.0201 - val_accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 229s 92ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.0200 - val_accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f673c7b7670>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with rnn, k=2\n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "898a673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1047/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1047/bias:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1048/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1048/bias:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1049/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1049/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1047/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1047/bias:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1048/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1048/bias:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1049/kernel:0', 'graph_like_model_32/graph_res_layer_94/graph_step_layer_189/adj_updater_189/conv2d_1049/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 215s 84ms/step - loss: 0.0376 - accuracy: 0.9842 - val_loss: 0.0271 - val_accuracy: 0.9887\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 0.0225 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 211s 84ms/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.0200 - val_accuracy: 0.9921\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0163 - accuracy: 0.9936 - val_loss: 0.0190 - val_accuracy: 0.9926\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0153 - accuracy: 0.9939 - val_loss: 0.0178 - val_accuracy: 0.9929\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0142 - accuracy: 0.9943 - val_loss: 0.0172 - val_accuracy: 0.9932\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.0178 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0132 - accuracy: 0.9948 - val_loss: 0.0167 - val_accuracy: 0.9934\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 212s 85ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.0153 - val_accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 212s 85ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0154 - val_accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f673c77f580>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without rnn, k=2, ident@enc\n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "90d16bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1257/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1257/bias:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1258/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1258/bias:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1259/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1259/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1257/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1257/bias:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1258/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1258/bias:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1259/kernel:0', 'graph_like_model_39/graph_res_layer_115/graph_step_layer_231/adj_updater_231/conv2d_1259/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 214s 84ms/step - loss: 0.0389 - accuracy: 0.9839 - val_loss: 0.0268 - val_accuracy: 0.9893\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 215s 86ms/step - loss: 0.0200 - accuracy: 0.9922 - val_loss: 0.0197 - val_accuracy: 0.9924\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.0187 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 0.0164 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 209s 84ms/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.0157 - val_accuracy: 0.9938\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 209s 84ms/step - loss: 0.0122 - accuracy: 0.9952 - val_loss: 0.0143 - val_accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 240s 96ms/step - loss: 0.0117 - accuracy: 0.9954 - val_loss: 0.0142 - val_accuracy: 0.9946\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 233s 93ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0149 - val_accuracy: 0.9943\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 209s 84ms/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0146 - val_accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f669c5d8f40>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without rnn, k=2\n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cb635f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1137/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1137/bias:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1138/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1138/bias:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1139/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1139/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1137/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1137/bias:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1138/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1138/bias:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1139/kernel:0', 'graph_like_model_35/graph_res_layer_103/graph_step_layer_207/adj_updater_207/conv2d_1139/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 214s 84ms/step - loss: 0.0389 - accuracy: 0.9837 - val_loss: 0.0291 - val_accuracy: 0.9879\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 211s 84ms/step - loss: 0.0221 - accuracy: 0.9909 - val_loss: 0.0226 - val_accuracy: 0.9912\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 211s 84ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 0.0217 - val_accuracy: 0.9915\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 211s 84ms/step - loss: 0.0165 - accuracy: 0.9935 - val_loss: 0.0186 - val_accuracy: 0.9927\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 211s 85ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.0176 - val_accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 211s 85ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 0.0168 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 211s 84ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.0167 - val_accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 212s 85ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.0164 - val_accuracy: 0.9936\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 216s 86ms/step - loss: 0.0130 - accuracy: 0.9948 - val_loss: 0.0166 - val_accuracy: 0.9936\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 210s 84ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0159 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f674e18ffa0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without rnn, k=-1, ident@enc\n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0b4a2408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1167/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1167/bias:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1168/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1168/bias:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1169/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1169/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1167/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1167/bias:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1168/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1168/bias:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1169/kernel:0', 'graph_like_model_36/graph_res_layer_106/graph_step_layer_213/adj_updater_213/conv2d_1169/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 221s 87ms/step - loss: 0.0461 - accuracy: 0.9808 - val_loss: 0.0350 - val_accuracy: 0.9851\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 215s 86ms/step - loss: 0.0272 - accuracy: 0.9886 - val_loss: 0.0273 - val_accuracy: 0.9887\n",
      "Epoch 3/10\n",
      "2458/2500 [============================>.] - ETA: 3s - loss: 0.0228 - accuracy: 0.9906"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1037563/3824383133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# without rnn, k=4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without rnn, k=4\n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "88d235a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1197/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1197/bias:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1198/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1198/bias:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1199/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1199/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1197/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1197/bias:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1198/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1198/bias:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1199/kernel:0', 'graph_like_model_37/graph_res_layer_109/graph_step_layer_219/adj_updater_219/conv2d_1199/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 219s 86ms/step - loss: 0.0443 - accuracy: 0.9812 - val_loss: 0.0390 - val_accuracy: 0.9835\n",
      "Epoch 2/10\n",
      " 986/2500 [==========>...................] - ETA: 2:01 - loss: 0.0290 - accuracy: 0.9876"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1037563/2667755316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# without rnn, k=-1, softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf27/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without rnn, k=-1, softmax \n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b4f9510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1227/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1227/bias:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1228/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1228/bias:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1229/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1229/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1227/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1227/bias:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1228/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1228/bias:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1229/kernel:0', 'graph_like_model_38/graph_res_layer_112/graph_step_layer_225/adj_updater_225/conv2d_1229/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "2500/2500 [==============================] - 212s 84ms/step - loss: 0.0393 - accuracy: 0.9835 - val_loss: 0.0282 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0218 - accuracy: 0.9911 - val_loss: 0.0233 - val_accuracy: 0.9906\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0188 - accuracy: 0.9924 - val_loss: 0.0203 - val_accuracy: 0.9918\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 207s 83ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.0201 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0156 - accuracy: 0.9938 - val_loss: 0.0176 - val_accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0143 - accuracy: 0.9943 - val_loss: 0.0175 - val_accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.0163 - val_accuracy: 0.9937\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 207s 83ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.0150 - val_accuracy: 0.9941\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.0153 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 208s 83ms/step - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.0148 - val_accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67346f02e0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without rnn, k=-1, sigmoid \n",
    "gnn.fit(train_dataset, steps_per_epoch=2500, validation_steps=500, epochs=10, validation_data=test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52881d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with 99.23@8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
